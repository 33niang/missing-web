---
title: 「程序」是怎样炼成的
type: docs
# draft: true 
---

# 「程序」是怎样炼成的

{{<hint danger>}}
🚧本章仍在施工中，内容并不完整且会发生变化，仅供先行阅读参考。
{{</hint>}}

{{<hint info>}}
近些年，仿佛有一股「少儿编程」「全民编程」之风席卷了中国：在大街小巷上，「编程辅导」的广告层出不穷；在中小学校里，程序设计的知识走进了课堂。即使你已经步入职场，类似「学编程知识，提升『生产力』」之类的培训广告仍然随处可见。在这股浪潮之下，我们有必要先回答一个更基本的问题——「程序」是什么？看完这一章，你将可以找到这些问题的答案：

- 什么是「程序」？「编程」是要做什么？
- 什么是 Python、C 语言、C++、Java……
- 程序是如何在电脑的硬件上运行的？

{{</hint>}}

早在《你缺计课》的第一章 [认识你的电脑]({{<ref "computer-and-its-components.md">}}) 我们就介绍过，电脑是由「硬件」和「软件」有机组成的整体。事实上，平板电脑、手机、智能手表——我们身边的一切智能设备，都由硬件和软件组成。这其中，「硬件」对应着电路、芯片以及各种外部设备，而软件就对应着各种各样的**计算机程序**，简称**程序**。

我们在电脑上使用的 Word 和浏览器、在手机上聊着的微信和 QQ、在平板上看着的各种视频 app，它们就是一个个程序。而 Windows、iOS、安卓这些操作系统，它们亦是一类特殊的程序。人们把「编写程序」的过程简称「编程」，这是今天许多人的工作。也许你对这项工作充满了好奇：我们今天使用的各种各样的程序，是如何被设计出来的呢？又或许你会疑惑：这些千变万化的程序，是怎么在冷冰冰的硬件上运行的呢？本章就让我们揭开「程序」这个熟悉又陌生之物的面纱，带你了解它背后的秘密。

## 程序？菜谱！

### 化繁为简的程序思维

让我们先来看一个生活中的「做菜」情景。「番茄炒蛋」是一道经典的家常菜，我们可以将烹饪它的过程归纳为这样的 5 个步骤：

- 准备材料：打蛋、洗净番茄切块；
- 单独炒鸡蛋：将鸡蛋炒至基本成型但保持嫩滑的状态，待用；
- 单独炒番茄：将番茄炒至变软，略开始出汁的状态；
- 合并一起炒，调味：将之前炒好的鸡蛋倒入，翻炒均匀，加入调味料；
- 出锅。

对于会做菜的读者，即使你从来没有炒过番茄炒蛋，看过这份菜谱之后，你也应该可以大差不差地将它做出来。然而，如果你是一位没有炒菜经验，甚至从来没有下过厨房的读者，这份步骤就略显笼统了。在这种情况下，我们可以先约定几个最简单、最基本的「操作」，如「切」「洗」「翻炒」等。这些操作十分机械化，可以在很短的时间内掌握它们。借助这些基础操作，我们的番茄炒蛋菜谱就可以改写为：

{{<columns>}}
- 准备材料：
  - **洗** *番茄* 3 个 → 得到「洗净的番茄」；
  - **切** *洗净的番茄* → 得到「番茄块」；
  - **打** *鸡蛋* 4 个 → 得到「鸡蛋液」；
- 单独炒鸡蛋：
  - **点火**；
  - **向锅中加入** *油* 20 mL；
  - **等待** 1 分钟；
  - **向锅中加入** *鸡蛋液*；
  - **翻炒** 2 分钟；
  - **熄火**；
  - **从锅中取出** *炒好的鸡蛋* → 得到「炒好的鸡蛋」；
<--->
- 单独炒番茄：
  - **点火**；
  - **向锅中加入** *油* 10 mL；
  - **等待** 40 秒；
  - **向锅中加入** *番茄块*；
  - **翻炒** 4 分钟；
- 合并一起炒：
  - **向锅中加入** *炒好的鸡蛋*；
  - **翻炒** 1 分钟；
  - **向锅中加入** *盐* 2 g；
  - **翻炒** 1 分钟；
  - **熄火**；
- 出锅：
  - **从锅中取出** *番茄炒蛋* → 得到「番茄炒蛋」。
{{</columns>}}

在这份新的详细版菜谱中，只包含 10 种基本操作，并且对每一步的操作，都用定量的方式来确定它们。同时，我们给整个做菜过程的「中间产物」都起了名字，例如「均匀的鸡蛋液」「番茄块」，这样可以最大程度地避免歧义。理论上，借助这样的一份新菜谱，即使是完全没有烹饪经验的人，也可以在简单培训后，照着它完成任务。

我们把这种通过组合利用少量、基础的操作，完成一项庞大、复杂的任务的思维，叫做「程序思维」。在计算机的世界里，硬件本身只能「理解」少量最基本的操作，如最基本的算术运算，以及「读取文件」「显示内容」等简单的对外交互。「程序」其实就是一份菜谱：像我们上面展示的那样，通过组合运用这些基本操作，实现各种各样的功能；而编程的过程，就是我们利用程序思维来编写这样的「菜谱」的过程。而这份番茄炒蛋的菜谱，本质上亦是一个「程序」，只不过执行它的硬件并非半导体芯片，而是我们人类。

在这个番茄炒蛋的菜谱中，我们将所有操作完全固定——从食材的量到翻炒的时间，都以具体的数字进行了规定。这样就降低了「硬件」的执行成本。然而，在现实生活中，起锅烧油所需要的时间可能与油的品质、气温、油量的多少等因素有关，而翻炒的时间也和食材的新鲜程度、切片时的厚度等挂钩。这种「固定一切」的思路，让整个程序过于死板，对环境没有适应能力。为此，我们再引入一种这样的操作：

- **如果** *番茄块* 还没有变软：
  - 再 **翻炒** 30 秒；
- **否则**：
  - 什么也不做。
  
如果说原来的程序是「做完一件事，就顺着做下一件事」的「一刀流」，那么在引入这种「如果」操作后，我们的程序长出了「分支」。在番茄比较生、气温比较低，或者水放少了的情况下，程序会进入「再翻炒 30 秒」这一支；而当番茄质地偏软、天气炎热，又或者油的品种不同时，程序就会选择什么也不做，然后继续向后运行。我们把原来的程序结构称为「顺序结构」，而这种引入「如果」的结构称为「分支结构」。

可是，分支结构只能实现「二选一」，通过嵌套多个分支也只能实现「三选一」「四选一」，程序能走出的道路终究是有限的。上面的例子让我们得以给不太好吃的番茄多炒 30 秒，可是如果 30 秒还是不够呢？进一步，在极端的情况下，再多 1 分钟也可能不够；而另一些时候，原本设定的 4 分钟翻炒可能已经多了一把「火」。分支结构在这样的情况下，「心有余而力不足」。为了解决这个问题，我们只能再采用一种新的操作：

- **当** *番茄块* 还没有变软 时：
  - 再 **翻炒** 30 秒。

乍一看，这个操作和刚刚提到的「如果」挺相似，但是它们的含义完全不同。这个操作是说，只要「番茄块还没有变软」，就一直重复不断地执行「翻炒 30 秒」这一步。只有某时刻，「番茄块还没有变软」不满足了，才能离开这个「轮回」，继续执行后面的流程。这样的结构称为「循环结构」，顾名思义，它的作用就是在一定的条件下，不断重复地做同一件事，直到这个条件不再成立。相较之下，「分支结构」也需要检查某个条件，但是即使条件满足，也只会选择某个分支执行一次。

> 分支结构和循环结构有明显的不同，但是，只要再引入一种操作，就能让分支结构「变」为循环结构。这个操作是什么呢？答案就是「跳转到第 x 步」，其中 x 是某步操作的编号。例如，下面的程序没有使用循环结构的「当」操作，却实现了和上面的程序完全一样的效果。
> 1. **如果** *番茄块* 已经变软：
>   - **跳转到** 第 4 步；
> 2. **翻炒** 30 秒；
> 3. **跳转到** 第 1 步；
> 4. 什么也不做。
>

事实上，我们可以将原本固定的 4 分钟翻炒直接替换为上面的循环。这样，我们的程序就会从一开始就根据番茄是否变软来控制翻炒的时间，实现了「具体问题具体分析」。进一步，我们还可以把循环体中的「30 秒」缩得更短，这样程序控制的精度就越高。

顺序、分支和循环结构是程序的三种基本控制结构——事实上，**只需要**这三种结构，世间一切复杂之事，就都可以用程序思维分解为基础操作的组合。你不妨现在思考一下身边各种各样的事：小到日常生活中的鸡毛蒜皮，大到社会运行的底层原理，一切都可以归约成这三种结构组合之下的基本操作。这就是程序思维的力量，也是今天的数字世界能够诞生的重要基石。

### 编程语言

在上一小节中，我们设计了一个菜谱「程序」。对于这个程序的每一步，我们都使用完整的中文句子来描述它的含义。然而，世界上的语言有成千上万种。我们大可以使用不同的语言来描述这份菜谱——只要保持每一步的含义不变，那么整个程序的本质和功能就没有改变。例如，我们将原有菜谱的第二段「单独炒鸡蛋」译成英语，并不会改变做这道菜的流程。

- Scramble Eggs Alone
  - Light the stove;
  - Add 40 mL of oil to the pot;
  - Wait for 40 seconds;
  - Scramble for 3 minutes;
  - Turn off the stove;
  - Set scrambled eggs aside.

诸如中文、英语、法语这样的语言，是我们人与人之间沟通的「桥梁」，而借助这样的桥梁，我们才得以用菜谱来指导他人完成烹饪。而在真正的计算机程序的世界里，人们亦设计了无数种不同的「语言」，它们是我们人类和「机器」沟通的桥梁。

（这一节暂未完成）

### 算法

## 0 与 1 之间的舞蹈

至此，我们已经明白，通过各种各样的编程语言，借助程序思维，人们得以将需要完成的工作编写为「程序」；而通过对算法的研究，又能在极大程度上提升程序的效率，从而更有效地解决问题。然而，我们所认识的「程序」，与冷冰冰的芯片、导线、电路所构成的计算机硬件之间，依然还有着一层厚厚的「隔阂」。程序所奏响的思维之歌，是如何化为 0 与 1 之间的舞蹈的？下面，就由我们为你一一讲述。

### 程序、指令、机器代码

在 [万言皆数——字符与编码规则]({{<ref "characters-and-encodings.md">}}) 一章中我们提到，计算机中的一切信息都由电路承载；具体地说，每个信息都是由若干位 0 和 1 这样的二进制数字所组成，反映在电路上，就是「有电」「无电」之间的排列组合。为了实现程序在硬件上运行，自然而然地，我们首先就需要寻找「程序」在硬件上的表达方式。具体来说，是将程序的每一步用 0 和 1 来表达的方式。

在本章的第一节，我们构想了一个「番茄炒蛋」的程序，不过那时我们认为这个程序的「硬件」就是我们人类。现在，我们想要让一台炒菜机器「你缺饭课一号」也能执行这份菜谱程序。「你缺饭课一号」并不能看懂中文、英文这样的人类语言，它所能做的，就是不断地读取某处并排的 8 根导线上的信号（即 8 位二进制数），然后根据这组信号的值，执行一个简单的动作。假设「你缺饭课一号」的部分设计如下：

- 机器一共有 4 个用来装食材的碗，可以在烹饪过程中使用。
- 机器不断地读取一个 8 位的信号，并按照下面的规则选择动作：

  | 信号 | 功能 |
  | :--: | -- |
  |`0001xxyy`|洗一份食材。`xx` 决定食材的种类：`00` 代表番茄、`01` 代表青椒……<br/>`yy` 表示洗完之后的食材加在哪个碗里，一共有 `00` 至 `11` 四个碗可以使用。<br/>例如，信号 `00010000` 能控制机器洗一份番茄放到第 0 号碗里。|
  |`001000yy`|打鸡蛋。`yy` 决定打好的蛋放在哪个碗里。|
  |`001100yy`|切菜。将 `yy` 号碗中的食材全部切块。|
  |`01000xxx`|给灶台点火，并向锅中加入的油。其中，油的量为 {{<katex>}}10\times\overline{\text{xxx}}_\text{B}{{</katex>}} mL 。例如，`01000100` 对应的 `xxx` 是 `100`，这组信号会让机器点火后加入 {{<katex>}}10\times4=40{{</katex>}} mL 的油。|
  |`010010yy`|向锅中倒入碗 `yy` 中的全部内容。|
  |`1000xxxx`|在锅中翻炒 {{<katex>}}10\times\overline{\mathrm{xxxx}}_\mathrm{B}{{</katex>}} 秒。|
  |`1100xxxx`|等待 {{<katex>}}10\times\overline{\mathrm{xxxx}}_\mathrm{B}{{</katex>}} 秒。|
  |`1110xxxx`|向锅中加入 `xxxx` g 的盐。例如，`11100101` 对应的 `xxx` 是 `101`，这组信号会让机器向锅中加入 5 g 盐。|
  |`111100yy`|将锅中的所有内容倒到 `yy` 号碗中。|
  |`11111111`|熄灭灶台。|

那么，我们可以依次给这台机器发送下面的 24 条信号，机器就能按照菜谱精准地完成一道番茄炒蛋。

1. `00010000`（洗一个番茄放到 0 号碗中，我们要重复发送这个信号 3 次，因为我们需要 3 个番茄）
2. `00010000`（洗一个番茄放到 0 号碗中）
3. `00010000`（洗一个番茄放到 0 号碗中）
4. `00100001`（打一个鸡蛋放到 1 号碗中。为了实现打 4 个鸡蛋，这条得重复 4 次）
5. `00100001`（打一个鸡蛋放到 1 号碗中）
6. `00100001`（打一个鸡蛋放到 1 号碗中）
7. `00100001`（打一个鸡蛋放到 1 号碗中）
8. `00110000`（将 0 号碗中的食材全部切块，即将番茄全部切块）
9. `01000010`（点火，向锅中加入 20 mL 的油）
10. `11000110`（等待 60 秒，即 1 分钟）
11. `11110001`（将 1 号碗中的鸡蛋液倒入锅中）
12. `10001100`（翻炒 120 秒，即 2 分钟）
13. `11111111`（熄火）
14. `11110010`（将炒好的鸡蛋倒到 2 号碗中，备用）
15. `01000001`（点火，向锅中加入 10 mL 的油）
16. `11110000`（将 0 号碗中的番茄块倒入锅中）
17. `10001100`（翻炒 120 秒，即 2 分钟）
18. `10001100`（翻炒 120 秒，即 2 分钟，为了实现翻炒 4 分钟，我们只能分拆成两条指令来完成（为什么？））
19. `11110010`（将 2 号碗中炒好的鸡蛋倒入锅中）
20. `10000110`（翻炒 60 秒，即 1 分钟）
21. `11100010`（向锅中加入 2 g 盐）
22. `10000110`（翻炒 60 秒，即 1 分钟）
23. `11111111`（熄火）
24. `11110011`（将炒好的菜倒入 3 号碗中）

最终，我们可以在 3 号碗中得到一份 ~~美味的~~ 番茄炒蛋。如果我们把这 24 条信号记录在某种「你缺饭课一号」可以直接读取的设备上，并让「你缺饭课一号」能够自动地从这个设备逐一读取信号并执行，不就实现了整个过程的自动化运行了吗？我们把这样一条一条的信号称为「指令」（instruction），它是机器能够直接执行的最小单元。可以想象，要让一个程序在机器上运行，就需要把程序转变成一条条指令，并将这些指令按顺序装载进机器。我们将一个程序所对应的指令序列称为「机器代码」，又称为「机器语言代码」。

> 这个「存放指令的设备」对应到计算机上就是内存。诶——你是不是想到硬盘上去啦？的确，我们的电脑程序都是安装在硬盘上的（如果不知道的话，罚你重修 [认识你的电脑]({{<ref "computer-and-its-components.md">}})😡）。但事实上，你双击启动一个程序时，机器会首先把它加载到内存里，然后再从内存中一条一条取出指令运行。

在现实的计算机内部，CPU 就像上面的「你缺饭课一号」一样，不断地从内存中「取指令」，取出的指令以电信号的形式，通过「译码」来识别出功能。随后，CPU 按照设计好的规则执行相应的功能。显然，我们的计算机并不是用来炒菜的，它的本职工作就是「计算」。因此，在计算机的指令世界中，肯定不会有什么「洗菜」「翻炒」这样的指令；相反，在计算机中，常用的指令按照功能可以分成如下的几类：

- 数据传输指令：它们用来将数据在计算机内部各种地方传递，如从内存中转移到 CPU 内部，或者将 CPU 内部计算好的结果转移到内存。在「你缺计课一号」中，我们设计有 4 个装中间食材的「临时碗」和一个用来炒菜的「锅」。在 CPU 内部，也有类似的「临时存储数据」的结构，称为「寄存器」。数据传输指令的主要功能，就是将数据在内存和寄存器中转移。

  > 寄存器的读写速度非常非常快，远远快于内存。不过，现代的处理器中通常只有几个或几十个寄存器，每个寄存器仅能存放几十位的数据，因此对 CPU 来说，寄存器必须珍惜使用，因而需要频繁地进行数据传输。

- 算术与逻辑运算指令：它们用来执行各种各样的计算，包括算术运算和逻辑运算。算术运算就是诸如「加减乘除」这样的数字运算，而逻辑运算指的是「或与非」这些条件的判定。
- 比较与控制流指令：它们用来实现分支结构和循环结构，主要的功能就是「比较」「跳转」。例如，「无条件跳转」指令在执行后，CPU 就不再会继续执行下一条指令，而是转移到机器代码中的另一处开始运行；而「大于则跳转」指令则会根据两个数的大小关系来决定要不要跳转。
- 机器控制指令：它们可以用来控制整个计算机的运转，包括停机、重置等。

随着计算机技术的不断发展，如今，我们常用的电脑 CPU 已经支持上千种不同的指令，上面所展示的只是这个庞大系统的冰山一角。为了让我们使用编程语言编写的程序能够在 CPU 上运行，就需要将它们转换成由指令组合而成的机器代码。机器代码存放在可执行文件——也就是 `.exe` 文件——当中，我们双击运行一个程序，本质就是将它的机器代码装入内存然后执行。因此，我们在电脑上安装的各种各样的软件，本质就是存放着各种各样的程序的机器代码。

显然，这个将「用编程语言编写的程序」转换为机器代码的过程并不轻松——在番茄炒蛋的世界里，一共只有十来种操作，但我们手工按照原始的程序（即本章开头的「番茄炒蛋菜谱」）编写出在「你缺饭课一号」上运行的机器代码也不是容易的事；而当这一切面对的是有上千种指令，操作的类型更是不计其数的计算机世界时，难度更是迈上了一个台阶。好在，早在上个世纪中叶，电子计算机问世之后不久，人们就设计出了自动完成这个过程的程序。借助它，机器能自动地将使用编程语言编写的程序转换成机器代码。我们把这个过程叫做「编译」（compile），而这种程序称为「编译器」（compiler）。

> 编译器也是一个程序，那它自己是怎么由程序转换成机器代码的呢？你可以这样理解：第一个编译器是人们用机器代码直接编写的，而当它发展得足够完善之后，人们就可以改用编程语言来设计它，然后由它来编译它自己。这个性质称为编译器的「自举」。
>

显然，不同的编程语言需要不同的编译器，同一种编程语言也可以有多种不同「品牌」的编译器。例如，C/C++ 最常用的编译器为「GCC」[^1]「Clang」和「微软 Visual C++ 编译器」，它们分别是今天 Linux、macOS 和 Windows 三大操作系统自身主要使用的编译器。Java 则使用「Oracle JDK」或「OpenJDK」提供的编译器——在电脑上玩过电子游戏《我的世界》（*Minecraft*）的读者肯定对这些名字不陌生。

有一些语言，比如 Python，则选择了另外的思路——比起事先将整个程序全部编译成机器代码，这些语言选择在程序运行时再完成转换。尽管最终实质上都将程序变成了对应功能的机器代码，但我们把这样的方式叫做「翻译」或「解释」（interpret），对应的工具则称为「翻译器」或「解释器」（interpreter）。CPython[^2] 是 Python 最常用的解释器，也是事实上的「官方解释器」——如果你在其他地方学习过 Python 编程，你安装的那个可以在 `>>>` 之后给出单个命令并执行的工具，就是 CPython 解释器。

[^1]: 事实上应该叫「GCC C 编译器」和「GCC C++ 编译器」，不过人们一般都用 GCC 代指它们。
[^2]: 之所以叫「CPython」是因为它是用 C 语言写的。这也提醒了我们，一种编程语言的编译器（解释器）并不一定要用这种语言自身来编写。

编译器和解释器解决了从「程序」到「机器代码」的跨越：借助它们的力量，我们设计的各种程序终于得以在硬件上运行。不过，我们说到这世界上的编程语言有成百上千种，那 CPU 所使用的指令难道都是一样的吗？进一步说，难道世界上所有的计算机，都使用着相同的指令设计吗？答案显然是否定的。事实上，它们不仅不一样，背后还像 [浏览器]({{<ref "browsers-and-how-to-choose.md">}}) 那样，有着一段「明争暗斗」的历史。

### 指令集的明争暗斗

#### 从 8086 到 x64

在上一小节，我们构想了一台「你缺饭课一号」，这台炒菜机器有 4 个「临时碗」，能够接受 8 位长度的指令来执行炒菜动作。我们在上文的表格中详细约定了每一种类型的指令的形式和功能。事实上，我们完全可以采用不同的指令格式、不一样的指令长度，甚至也可以选择再增加或者删除一些指令（比如将「点火」和「倒油」功能分拆成两种指令，或者将一些功能合并成一条新的指令），设计出「你缺饭课二号」「你缺饭课三号」……我们把这样的一种对「指令种类、形式、长度等一切相关的东西」的约定，称为「指令集架构」（instruction set architecture，ISA），简称「指令集」。

我们能自然而然地想象到，在计算机的世界里，指令集肯定也不会是只有一枝独秀的天地，而是百花齐放的花园。但这回，我们的想象与现实之间，有一点点小差距。这个故事还要从 1978 年说起。那一年，美国半导体公司英特尔推出了一款名为「8086」的处理器，它拥有 8 个寄存器，**每个寄存器可以存放 16 位的数据，因此被人们称为「16 位处理器」**。8086 支持约 100 种不同的指令，每种指令长度不一，最短者为 1 字节（8 位），最长者为 6 字节（48 位）。

在那个年代，与 8086 同台竞争的 CPU 数量不少，它们大都使用同样的 16 位设计，但是在指令风格、指令数量等方面有差异。按照正常的剧本来说，它应该会和竞品一起在市场上打得「有来有回」，然后一同走向历史的坟墓。可是，历史总是充满未知和巧合。当时，知名的电脑公司 IBM（在 [以密码之剑护网安之城]({{<ref "introduction-to-cryptology.md">}}) 等多个章节中，我们提到过它的名字）正苦于自己过去几年在个人电脑领域的失败中：IBM 此前拿手的是「大型机」的设计，他们传统的设计流程无法适应低端、廉价、小型的个人电脑市场。在痛定思痛的基础上，IBM 做出了一个大胆的决定：不再拘泥于自己设计 CPU 等硬件，而是把选择交给市场。这时，8086 就入了 IBM 的法眼。

> 「全链条覆盖」和「交给市场」是设计复杂系统的两种思路。历史已经多次告诉我们，这二者间没有固定的「谁好谁坏」的关系，我们必须结合历史条件、产业性质来具体问题具体分析。
>

1981 年，IBM 发布了名为「IBM PC」的个人电脑，选择 8086 的兄弟型号 8088 作为 CPU。在 8088 处理器的加持下，IBM PC 取得了性能和价格之间不错的平衡，迅速在市场上占有了一席之地。同时，IBM 还开放了 IBM PC 的技术参考资料，这意味着其他厂商都可以自由设计、生产和出售与 IBM PC 兼容的软件和硬件，甚至是设计出与 IBM PC 本身兼容的电脑。同时，微软也加入了这个 ~~脆弱的~~ 同盟，提供了一套稳定且实用的操作系统 MS-DOS，更是吸引来了许多软件开发商，它们纷纷将自己的软件编译成能在 IBM PC 上运行的机器代码来发布。在这样三重因素的催化之下，IBM PC 很快成为了「个人电脑」的代名词，命运的齿轮从此开始转动。

1982 年，英特尔发布了 8086 的后继产品 80286，它与 8086 使用相同的指令集，但提升了运行的主频，并增强了对内存的访问能力。而到了 1985 年，第三代产品 80386 横空出世。与 8086 和 80286 的显著区别是，80386 将 8 个寄存器的大小升级为了 32 位，因此我们称它为 **「32 位处理器」**。不过，英特尔并没有选择让它与 8086 / 80286「割席」，而是通过在它们原本的指令集上额外引入一批指令来支持 32 位相关的功能。这意味着**原本能在 8086 / 80286 上运行的软件可以无需重新编译直接使用**，同时以后发布的新软件则可以选择针对 32 位特性引入更强大的功能。这种「向后兼容性」使得 80386 再一次颠覆市场，再加上便捷易用的 Windows 操作系统的「横空出世」，8086 / 80286 / 80386 这三代处理器所使用的指令集逐渐成为了「事实上」的电脑 CPU 标准。由于这几代产品都使用「80x86」来命名，人们把这套指令集命名为「x86」。

x86 的巨大成功还吸引来了其他一些 CPU 厂商，它们从英特尔那里拿到授权，生产自己设计的，但是使用 x86 指令集的处理器。这其中就包括 AMD。1991 年，AMD 发布了 80386 的「复刻版」Am386，随后又发布了 80486 的复刻版 Am486。它们在指令集方面与 80386 / 80486 完全兼容，凭借更低的价格开始有力地与英特尔竞争。不过，尽管 AMD 主打价格优势，但是这种总是跟在别人后面模仿的商业路线注定无法成功——芯片技术发展的速度远远快于人们的想像，等复刻品出来，「正品」都更新一代了。如果按照剧本发展的话，AMD 应该会最终没落于众多 x86 兼容芯片厂商之中，在历史的长河里留下不轻不重的一笔。

然而，转机发生在新世纪来临前的黎明。随着信息技术的飞速发展，人们发现 32 位设计已经有些「捉襟见肘」：32 位的寄存器只能存放最大为 {{<katex>}}2^32-1=4\,294\,967\,295{{</katex>}} 正整数，而当计算任务超过这个数字时，就只能采用拆分或其他的方法，这很大程度上影响了计算效率。同时，受制于同样的原因，32 位架构最大只能使用 4 GB 的内存，尽管在 2000 年前后，4 GB 内存已经是一个巨大的数字，但是当时的人们已经卓有远见地看到了未来。因此，引入新的 64 位架构，成为包括英特尔在内的有志之「司」都开始考虑的问题。

我们回看从 80286 到 80386 的 16 位向 32 位的跨越，当时英特尔选择的是在原有指令集的基础上添加新的指令，这样可以在兼容以前的老旧应用时，增加新的功能。然而，在 32 位迈向 64 位这一次，英特尔把步子迈得太大了——他们直接重新设计了一套纯 64 位的指令集（称为 IA-64）。这 IA-64 采用了新的设计思想，支持包括高效的并行计算在内的许多新功能。唯一的问题是：它与 x86 不兼容。原本的各种软件都需要换用 IA-64 的编译器重新发布新的版本。IA-64 一经发布，世人反应冷淡，这一次英特尔没能成功。

一直以来，我们都经常看见「官方逼死同人」的事情发生，不过这一次，是「同人倒逼官方」。「既然英特尔自己搞 64 位弄砸了，那不正是我 AMD 的好时机吗？」于是，AMD 在 x86 的基础上，直接把原有的 8 个寄存器扩充成 64 位，再引入一批针对 64 位操作的新指令，不仅实现了 64 位的功能，还在最大程度上保持了对原有 32 位应用的兼容性。2003 年，AMD 发布 Athlon 64，这是第一块 64 位的 x86 处理器，一经推出，好评不断，随后的两年间，支持 64 位的操作系统和应用软件就开始出现在市场上了。AMD 给这种指令集改了个名，叫「AMD64」。这是一次「同人」作品的胜利。

此时的英特尔有点尴尬——自己推出的 IA-64 无人问津，而身为「同人作者」的 AMD 反而给自己的 x86 架构升级了。不过，日子还得过嘛……2004 年，英特尔发布了具有里程碑意义的「奔腾 4 Prescott」（Pentium 4 Prescott）处理器。它的里程碑意义之一，就是使用了 AMD64 架构，成为了英特尔的第一款 64 位的 x86 处理器。曾经，人们总认为 AMD 的产品是英特尔的仿制器，可是这回，同人把官方倒逼了。

当然，英特尔肯定不会在明面上使用「AMD64」这个名字。他们把它改名成了「Intel 64」。世人一想，你们这各自拉扯，我们到底应该用哪个名称呢？于是，人们索性用「x86-64」来表示这种「64 位的 x86 指令集」，以和原本纯 32 位的 x86 作区分。后来，人们也会把「x86-64」简称为「x64」，用来表示这种指令集。后来的故事，就是在本作品的第一章 [认识你的电脑]({{<ref "computer-and-its-components.md">}}) 中所介绍的了那样了——英特尔和 AMD 成为了 x86-64 指令集的两大霸主，开始统治着全世界的电脑 CPU 市场，直到今天。

> 得益于这种兼容性，64 位的 CPU 上既可以运行 64 位的操作系统，也可以运行 32 位的操作系统。而在 64 位的操作系统下，也可以同时存在 32 位和 64 位的软件。目前，几乎所有的电脑都在 x86-64 上运行 64 位的操作系统，不过仍然有许多 32 位的软件正在和 64 位的软件共处。打开【任务管理器】，展开【详细信息】并转到【进程】页面，正运行在 32 位的软件后方会用【(32 位)】标出。
>
> ![任务管理器中的 32 位标记](program-and-arch/32bit_in_taskmgr.png#center)
>

对于大多数读者的电脑，右键桌面上的【此电脑】选择【属性】，就能在【设备规格】一栏下方的【系统类型】看见这样一句话：

{{<hint quoting>}}
64 位操作系统, 基于 x64 的处理器
{{</hint>}}

其中「64 位操作系统」说明操作系统本身，以及其上运行的大部分软件都是 64 位的；而「基于 x64 的处理器」，说的就是 x86-64。

![系统设置中的指令集说明](program-and-arch/x64_in_settings.png#center)

#### 统治移动世界的 ARM

尽管自 8086 开始，x86 指令集就在个人电脑领域快速抢占市场。然而，「计算机」不止局限于我们桌子上的个人电脑——无论是手机、平板电脑、MP3 这一众「智能设备」，还是日用的电视机遥控器、电高压锅、洗衣机等诸多电器，它们的内部也拥有像电脑一样的 CPU 来实现自动控制和人机交互，因而也是一种形式的「计算机」（称为「嵌入式计算机」）。而在这片天地属于移动和嵌入式设备的天地中，又是另一片勃勃生机的境界。

1985 年，来自英国的艾康电脑公司（Acorn Computers）发布了一款称为「ARM1」的原型处理器，「ARM」的含义是「Acorn 精简指令集机器」（Acorn RISC[^3] Machine）。作为一款 32 位的处理器，它与同时代包括 80286 在内的 CPU 最大的不同是：它具有极为简单的设计，只有约 25 条基本指令，并且舍弃了许多其他处理器中的复杂设计。这种指令集就被称为「ARM」指令集。次年，用于量产的 ARM2 投产，精简的设计使得它只需消耗极少的电能，就能有出色的性能表现。这为它日后在便捷式设备和微型设备中的大放异彩埋下了伏笔。

[^3]: 是「精简指令集电脑」（Reduced Instruction Set Computer）的缩写。

时间来到了 90 年代。那时，苹果公司正计划开发一款可以拿在手上触控操作的「掌上电脑」——可以看成今天 iPad 的前身。低功耗的 ARM 处理器与苹果的产品构思不谋而合。于是，1990 年，苹果、安谋电脑和另一家公司进行了分割重组，直接成立了一家名为「ARM」的公司，中文常译为「安谋」。这「ARM」的名字直接来源于 ARM 系列处理器和 ARM 指令集，不过被重新解释为「高级精简指令集机器」（Advanced RISC Machines）。1993 年，苹果推出了著名的掌上电脑「Apple Newton」（中文常称为「牛顿」），使用的就是 ARM 610 处理器。

在这几年的时间里，尽管 ARM 处理器的性能不断提升，但是其精简的结构设计和低功耗的特点没有改变。安谋敏锐地嗅到了这种低功耗 CPU 市场的商机，开始从「造芯片」转向「卖解决方案」——即，安谋自己不再进行 CPU 的制造和出售，而是只进行 ARM 指令集的升级、维护，并在 ARM 指令集上设计出芯片的原型，出售给其他的芯片公司。其他公司在购得授权后，可以在这原型上进行扩展、组合，并最终设计、制造出自己品牌的，采用 ARM 指令集的 CPU。站在后来者的视角，我们不得不感叹这种模式的强大之处：这让越来越多的企业得以入局市场，带来良性的竞争和发展，而安谋则只需依靠授权费用就能大赚一笔，又得以继续让 ARM 指令集变得更加强大。

进入新世纪以来，移动设备和嵌入式系统迎来崛起。如果说 x86（以及 x86-64）是事实上的个人电脑指令集标准，那么 ARM 无疑则是事实上的移动设备指令集标准。一方面，高通、三星、联发科、德州仪器等老牌芯片厂商「入局」ARM，让 ARM 指令集的 CPU 选择越来越多；另一方面，智能手机、平板电脑等便携式电子设备的快速发展，又反过来促进了相关芯片产业的发展。

今天，ARM 指令集的 CPU 在我们身边无处不在。无论是 iPhone 使用的 A 系列 CPU，还是各品牌安卓手机所使用的「高通骁龙」「联发科天玑」等系列 CPU，又或是华为手机使用的「海思麒麟」CPU，它们都使用的是 ARM 指令集。任天堂的掌上游戏机 Nintendo Switch 使用的是 NVIDIA Tegra X1 CPU，同样采用 ARM 指令集。而在许多小型智能设备，如门禁机、打卡机、扫地机器人中使用的「STM32」系列芯片，也使用的是 ARM 指令集。说 ARM 指令集「统治」了移动世界，一点都不为过。

> ARM 指令集是一个非常「灵活」的指令集，面向不同的应用场景，它有许多不同的版本，可以对各种功能进行「选配」。例如，用在打卡机上的 ARM 指令集，肯定就要比用在智能手机上的要简单得多。

看到这儿，我们自然而然会想到一个问题：现在，手机和平板电脑的性能已经非常强大，玩游戏、剪视频，甚至轻度的办公都可以胜任，这证明 ARM 能在低功耗的同时具有非常高的「上限」，并不是只能被局限在移动设备上。那为什么在个人电脑领域，仍然是 x86-64 的天下呢？这个问题我们能想到，安谋肯定也能想到，高通、华为、苹果这样的芯片设计公司显然也能想到。只是，这其中最大的问题，又要回到「软件」头上。在下一节「应用生态」，我们会继续介绍这个问题。

#### 用开放拥抱自主

无论是 x86-64 还是 ARM，它们都有一个特点：受商业公司控制。虽说除了英特尔和 AMD 之外，仍然有数家企业取得了一部分 x86-64 的授权，但是它们的市场都可以视为「忽略不计」，同时英特尔和 AMD 这俩巨头肯定也不会舍得将蛋糕再分给他人。而在 ARM 这边，想要获得 ARM 指令集的授权，也需要向安谋支付高昂的授权费用。在软件的世界里，我们有「开源软件」这样充满自由精神的存在，那在指令集的世界中，是否存在类似的想法呢？答案是肯定的。

2010 年，加州大学伯克利分校提出了一套名为「RISC-V」指令集。这是一套「开源指令集」，它可以被自由地用于任何目的，允许任何人设计、制造和销售使用该指令集的芯片和软件而不必支付任何专利或授权费用。在公开之后，RISC-V 指令集获得了来自许多高校、企业和研究机构的关注——毕竟，和开源软件的「众人拾材火焰高」一样，共同建设 RISC-V 指令集，最终亦能使自己受益。十多年来，RISC-V 的关注度一路高涨，并且也已经有了商业的和开源的芯片实现，如阿里巴巴推出的玄铁 910 CPU，以及中科院的「香山」开源 CPU。尽管目前对 RISC-V 的实际应用仍然处于实验室阶段，但我们可以期待它未来的表现。

除了 RISC-V 之外，我国芯片公司龙芯也在 2021 年发布了一套全新的指令集「LoongArch」，中文称「龙架构」，并先后推出了 3A5000、3A6000 两代 CPU 产品，具有极为出色的性能表现。LoongArch 除了基础部分开源外，还有一个更为重要的性质——「自主」。例如，尽管理论上只要购买授权就能设计出自己的 ARM 指令集处理器，但是「卖不卖给你」这事儿，也得由人家说了算。2019 年，中美贸易摩擦正激烈的时候，网上就有人开始讨论 ARM 是否会停止对华为的授权。尽管目前华为拥有 ARMv9 的永久授权，但当下的国际形势风云变幻，谁也无法预料「脱钩」是否真的会发生。这不断地提醒着我们：自主，很重要。

就像 LoongArch 的诞生一样，「开放」和「自主」并不矛盾；相反，它们在很多时候，是一体两面的统一体。用开放拥抱自主，是当下处于变局之中的我们最好的选择。

### 应用生态与转译

在介绍 ARM 指令集时，我们留下了一个疑问：明明 ARM 指令集的上限很高，功耗又更低，可为什么今天在个人电脑领域，并没有与 x86-64「平分秋色」？进一步说，RISC-V、龙架构这些新兴指令集，为什么难以在市场上推进？一切的根源便是由「软件」所构造起来的「应用生态」。

由于不同指令集的 CPU 采用了不一样的指令设计，原先为一种指令集编译的软件，无法直接在另一种指令集的处理器上运行。例如，在 ARM 指令集的 CPU 上，无法直接运行 x86-64 的机器代码。这使得使用指令集的 CPU 之间形成了一层层厚厚的「墙」，软件难以直接跨越。我们把为某个指令集编译的所有软件组成的整体，称为这个指令集的「应用生态」。

显然，由于 x86 架构在历史上的成功，今天的 x86 和 x86-64 指令集，构建起了巨大无比的应用生态。从 Windows 操作系统本身开始，我们所使用的几乎一切电脑软件，都提供了为 x86 或 x86-64 指令集编译的机器代码。我们能够在网上直接下载一款 app 并双击运行，就是因为大家已经默认所有人都在使用 x86-64 指令集的 CPU。如果我们需要改用 ARM 指令集的 CPU，最根本的办法，就是要求所有软件厂商，使用各编程语言针对 ARM 的编译器，重新编译它们的软件。这显然有一定的难度。

如果存在比较封闭的软件生态（即软件的数量较少、且软件厂商可控），只要有足够的时间，这么做并非完全不可行。2020 年，苹果发布了采用 ARM 指令集的电脑处理器 Apple M1，并推出了搭载该芯片的笔记本电脑——此前，苹果的电脑产品亦使用英特尔的 x86-64 处理器。由于本身 macOS 的软件支持就有限，同时苹果又有极强的行业号召力，到了今天（2024 年），在 ARM 指令集上的苹果电脑已经有了相当数量的软件支持，在日常办公、平面设计乃至软件开发等领域已经有了不错的体验。

既然让软件厂商在一夜之间全部完成转变不太现实，人们想出了另一种折中的方案：能不能设计一种「现场翻译」，当需要在一种指令集上运行另一种指令集的机器代码时，一句一句将指令「翻译」为本指令集的指令呢？这就是「转译」方案。目前，对于那些过去编译的、针对 x86-64 指令集的应用，苹果在 ARM 指令集上使用称为「Rosetta 2」的转译器来运行。然而，转译最大的问题便是性能：原本一条指令的事，由于转译本身需要时间开销，可能就变成许多条指令才能完成了。

如果说苹果借助自己的影响力和 Rosetta 2 转译器，实现了差强人意的从 x86-64 到 ARM 的过渡，那这个问题在 Windows 身上，就不那么顺利了。尽管 Windows 自身早已推出了支持 ARM 指令集的版本，但面向 Windows 平台的软件多如牛毛，微软不可能亲自逐个联系他们，要求使用针对 ARM 的编译器重新编译软件并发布。因此，当 Windows 需要从 x86-64 迁移到 ARM 时，要比苹果更加依赖转译——然而，转译带来的性能损失是客观存在的，这注定造就了在 ARM 指令集上，Windows 的软件生态更难构建。直到今天，虽然市面上有少量采用 ARM 指令集 CPU 的 Windows 电脑，但它们的使用体验，仍然有待提高。


## 练习

